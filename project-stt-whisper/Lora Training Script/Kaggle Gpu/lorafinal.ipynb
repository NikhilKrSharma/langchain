{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11407595,"sourceType":"datasetVersion","datasetId":7145814}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets transformers[torch] soundfile librosa accelerate evaluate jiwer --quiet\n!pip install --upgrade transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T20:48:16.995780Z","iopub.execute_input":"2025-04-14T20:48:16.996780Z","iopub.status.idle":"2025-04-14T20:48:35.907436Z","shell.execute_reply.started":"2025-04-14T20:48:16.996748Z","shell.execute_reply":"2025-04-14T20:48:35.906566Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nCollecting transformers\n  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.51.1\n    Uninstalling transformers-4.51.1:\n      Successfully uninstalled transformers-4.51.1\nSuccessfully installed transformers-4.51.3\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install -U transformers datasets accelerate peft\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T20:54:39.018985Z","iopub.execute_input":"2025-04-14T20:54:39.019829Z","iopub.status.idle":"2025-04-14T20:54:44.603672Z","shell.execute_reply.started":"2025-04-14T20:54:39.019792Z","shell.execute_reply":"2025-04-14T20:54:44.602751Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\nCollecting accelerate\n  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\nCollecting peft\n  Downloading peft-0.15.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.7/354.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading peft-0.15.1-py3-none-any.whl (411 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.0/411.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: accelerate, peft\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 1.3.0\n    Uninstalling accelerate-1.3.0:\n      Successfully uninstalled accelerate-1.3.0\n  Attempting uninstall: peft\n    Found existing installation: peft 0.14.0\n    Uninstalling peft-0.14.0:\n      Successfully uninstalled peft-0.14.0\nSuccessfully installed accelerate-1.6.0 peft-0.15.1\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T09:32:48.806006Z","iopub.execute_input":"2025-04-15T09:32:48.806649Z","iopub.status.idle":"2025-04-15T09:32:53.750932Z","shell.execute_reply.started":"2025-04-15T09:32:48.806625Z","shell.execute_reply":"2025-04-15T09:32:53.749887Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.16)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.19.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.3 fsspec-2024.12.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"Lora Model And Training Arguments","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers.git accelerate datasets peft librosa --quiet\n\nimport torch\nfrom datasets import load_dataset, Audio\nfrom transformers import (\n    WhisperFeatureExtractor,\n    WhisperTokenizer,\n    WhisperProcessor,\n    WhisperForConditionalGeneration,\n    Seq2SeqTrainingArguments,\n    Trainer\n)\nfrom peft import LoraConfig, get_peft_model, PeftModel\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\nimport os\n\ndataset_path = \"/kaggle/input/whisperlor/train-00000-of-00010.parquet\"\ndataset = load_dataset(\"parquet\", data_files=dataset_path)[\"train\"]\n\nnum_audio_files = len(dataset)\ntotal_duration_sec = sum(audio[\"array\"].shape[0] / audio[\"sampling_rate\"] for audio in dataset[\"audio\"])\nprint(f\"Total Audio Files: {num_audio_files}\")\nprint(f\"Total Duration (hrs): {total_duration_sec / 3600:.2f}\")\n\ndataset = dataset.remove_columns([col for col in dataset.column_names if col not in [\"audio\", \"text\"]])\n\nmodelname = \"openai/whisper-tiny\"\nlanguage = \"hi\"\ntask = \"transcribe\"\n\nfeature_extractor = WhisperFeatureExtractor.from_pretrained(modelname)\ntokenizer = WhisperTokenizer.from_pretrained(modelname, language=language, task=task)\nprocessor = WhisperProcessor.from_pretrained(modelname, language=language, task=task)\n\ndataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n\ndef prepare_dataset(batch):\n    audio = batch[\"audio\"]\n    batch[\"input_features\"] = feature_extractor(\n        audio[\"array\"], \n        sampling_rate=audio[\"sampling_rate\"]\n    ).input_features[0]\n    batch[\"labels\"] = tokenizer(batch[\"text\"]).input_ids\n    return batch\n\ndataset = dataset.map(prepare_dataset, remove_columns=dataset.column_names)\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n    \n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]):\n        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        \n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n        \n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n        batch[\"labels\"] = labels\n        \n        return batch\n\ndata_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n\nmodel = WhisperForConditionalGeneration.from_pretrained(\n    modelname,\n    device_map=\"auto\",\n    torch_dtype=torch.float32\n)\n\nconfig = LoraConfig(\n    r=32,\n    lora_alpha=64,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"SEQ_2_SEQ_LM\"\n)\n\n#This  Create custom PeftModel class for Whisper\nclass WhisperPeftModel(PeftModel):\n    def forward(self, input_features=None, **kwargs):\n        return self.base_model(input_features=input_features, **kwargs)\n\nmodel = WhisperPeftModel(model, config)\nmodel.print_trainable_parameters()\n\n# Custom trainer for Whisper\nclass CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        input_features = inputs.get(\"input_features\")\n        labels = inputs.get(\"labels\")\n        \n        outputs = model(input_features=input_features, labels=labels)\n        loss = outputs.loss\n        \n        return (loss, outputs) if return_outputs else loss\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./whisper-lora-hindi\",\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=1,\n    learning_rate=1e-3,\n    warmup_steps=50,\n    num_train_epochs=6,\n    fp16=False,\n    generation_max_length=128,\n    logging_steps=10,\n    save_strategy=\"epoch\",\n    save_total_limit=2,\n    remove_unused_columns=False,\n    label_names=[\"labels\"],\n    report_to=[],\n)\n\n# Save only LoRA adapter callback\nclass SavePeftModelCallback(TrainerCallback):\n    def on_save(self, args, state, control, **kwargs):\n        checkpoint_folder = os.path.join(args.output_dir, f\"checkpoint-{state.global_step}\")\n        adapter_folder = os.path.join(checkpoint_folder, \"adapter_model\")\n        kwargs[\"model\"].save_pretrained(adapter_folder)\n        return control\n\ntrainer = CustomTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=dataset,\n    data_collator=data_collator,\n    tokenizer=feature_extractor,\n    callbacks=[SavePeftModelCallback()]\n)\n\nmodel.config.forced_decoder_ids = None\nmodel.config.suppress_tokens = []\nmodel.config.use_cache = False\n\ntrainer.train()\n\nmodel.save_pretrained(\"./whisper-lora-hindi-final\")\nprocessor.save_pretrained(\"./whisper-lora-hindi-final\")\n\nprint(\"Training complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T21:32:13.613988Z","iopub.execute_input":"2025-04-14T21:32:13.614367Z","iopub.status.idle":"2025-04-14T21:53:25.038751Z","shell.execute_reply.started":"2025-04-14T21:32:13.614341Z","shell.execute_reply":"2025-04-14T21:53:25.037786Z"}},"outputs":[{"name":"stdout","text":"  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nTotal Audio Files: 1183\nTotal Duration (hrs): 2.74\ntrainable params: 589,824 || all params: 38,350,464 || trainable%: 1.5380\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/3728147076.py:137: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n  trainer = CustomTrainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1776' max='1776' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1776/1776 20:37, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.754700</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.098400</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.634300</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.430200</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.186800</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.998700</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.898200</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.710600</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.618200</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.524600</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.503000</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.462700</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.480700</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.417000</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.432600</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.419900</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.422900</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.402500</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.401500</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.384000</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.345600</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.358900</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.336700</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.312900</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.324000</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.347700</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.338800</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.315700</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.317500</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.297000</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.257700</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.245300</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.248800</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.241800</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.259800</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.242000</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.272300</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.250300</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.262400</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.251100</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.240500</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.262900</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.248000</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.242700</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.228200</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.264400</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.228600</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.236000</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.247400</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.218200</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.260800</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.256900</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.214400</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.221800</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.208000</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.221200</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.233900</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.174200</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.231800</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.187600</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.164600</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.145200</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.151700</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.154100</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.185100</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.176000</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.197600</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.184100</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.183400</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.175600</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.163900</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.169700</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.159700</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.172000</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.168400</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.179300</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.173400</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.155800</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.159700</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.165700</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.158400</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.153600</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.162800</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.163600</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.190900</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.172700</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.173400</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.154800</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>0.143900</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.127000</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>0.122600</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.115800</td>\n    </tr>\n    <tr>\n      <td>930</td>\n      <td>0.108600</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>0.109400</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.127400</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>0.118400</td>\n    </tr>\n    <tr>\n      <td>970</td>\n      <td>0.113100</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>0.115200</td>\n    </tr>\n    <tr>\n      <td>990</td>\n      <td>0.116900</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.108000</td>\n    </tr>\n    <tr>\n      <td>1010</td>\n      <td>0.108300</td>\n    </tr>\n    <tr>\n      <td>1020</td>\n      <td>0.114700</td>\n    </tr>\n    <tr>\n      <td>1030</td>\n      <td>0.110300</td>\n    </tr>\n    <tr>\n      <td>1040</td>\n      <td>0.116200</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.110400</td>\n    </tr>\n    <tr>\n      <td>1060</td>\n      <td>0.101800</td>\n    </tr>\n    <tr>\n      <td>1070</td>\n      <td>0.106200</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>0.127800</td>\n    </tr>\n    <tr>\n      <td>1090</td>\n      <td>0.110200</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.113000</td>\n    </tr>\n    <tr>\n      <td>1110</td>\n      <td>0.128200</td>\n    </tr>\n    <tr>\n      <td>1120</td>\n      <td>0.132900</td>\n    </tr>\n    <tr>\n      <td>1130</td>\n      <td>0.114500</td>\n    </tr>\n    <tr>\n      <td>1140</td>\n      <td>0.125400</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.111200</td>\n    </tr>\n    <tr>\n      <td>1160</td>\n      <td>0.100100</td>\n    </tr>\n    <tr>\n      <td>1170</td>\n      <td>0.118500</td>\n    </tr>\n    <tr>\n      <td>1180</td>\n      <td>0.108900</td>\n    </tr>\n    <tr>\n      <td>1190</td>\n      <td>0.096300</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.069400</td>\n    </tr>\n    <tr>\n      <td>1210</td>\n      <td>0.074400</td>\n    </tr>\n    <tr>\n      <td>1220</td>\n      <td>0.083400</td>\n    </tr>\n    <tr>\n      <td>1230</td>\n      <td>0.078600</td>\n    </tr>\n    <tr>\n      <td>1240</td>\n      <td>0.071300</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.070400</td>\n    </tr>\n    <tr>\n      <td>1260</td>\n      <td>0.082100</td>\n    </tr>\n    <tr>\n      <td>1270</td>\n      <td>0.080100</td>\n    </tr>\n    <tr>\n      <td>1280</td>\n      <td>0.077600</td>\n    </tr>\n    <tr>\n      <td>1290</td>\n      <td>0.078600</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.079200</td>\n    </tr>\n    <tr>\n      <td>1310</td>\n      <td>0.085800</td>\n    </tr>\n    <tr>\n      <td>1320</td>\n      <td>0.081400</td>\n    </tr>\n    <tr>\n      <td>1330</td>\n      <td>0.073900</td>\n    </tr>\n    <tr>\n      <td>1340</td>\n      <td>0.083600</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.067800</td>\n    </tr>\n    <tr>\n      <td>1360</td>\n      <td>0.066800</td>\n    </tr>\n    <tr>\n      <td>1370</td>\n      <td>0.070100</td>\n    </tr>\n    <tr>\n      <td>1380</td>\n      <td>0.077900</td>\n    </tr>\n    <tr>\n      <td>1390</td>\n      <td>0.082000</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.093100</td>\n    </tr>\n    <tr>\n      <td>1410</td>\n      <td>0.070600</td>\n    </tr>\n    <tr>\n      <td>1420</td>\n      <td>0.083900</td>\n    </tr>\n    <tr>\n      <td>1430</td>\n      <td>0.087200</td>\n    </tr>\n    <tr>\n      <td>1440</td>\n      <td>0.070500</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.070700</td>\n    </tr>\n    <tr>\n      <td>1460</td>\n      <td>0.065800</td>\n    </tr>\n    <tr>\n      <td>1470</td>\n      <td>0.071300</td>\n    </tr>\n    <tr>\n      <td>1480</td>\n      <td>0.083700</td>\n    </tr>\n    <tr>\n      <td>1490</td>\n      <td>0.053300</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.051300</td>\n    </tr>\n    <tr>\n      <td>1510</td>\n      <td>0.054200</td>\n    </tr>\n    <tr>\n      <td>1520</td>\n      <td>0.049300</td>\n    </tr>\n    <tr>\n      <td>1530</td>\n      <td>0.057300</td>\n    </tr>\n    <tr>\n      <td>1540</td>\n      <td>0.048600</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.046500</td>\n    </tr>\n    <tr>\n      <td>1560</td>\n      <td>0.056300</td>\n    </tr>\n    <tr>\n      <td>1570</td>\n      <td>0.051600</td>\n    </tr>\n    <tr>\n      <td>1580</td>\n      <td>0.067500</td>\n    </tr>\n    <tr>\n      <td>1590</td>\n      <td>0.054300</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.040400</td>\n    </tr>\n    <tr>\n      <td>1610</td>\n      <td>0.043000</td>\n    </tr>\n    <tr>\n      <td>1620</td>\n      <td>0.037400</td>\n    </tr>\n    <tr>\n      <td>1630</td>\n      <td>0.054000</td>\n    </tr>\n    <tr>\n      <td>1640</td>\n      <td>0.047500</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.045200</td>\n    </tr>\n    <tr>\n      <td>1660</td>\n      <td>0.050900</td>\n    </tr>\n    <tr>\n      <td>1670</td>\n      <td>0.050700</td>\n    </tr>\n    <tr>\n      <td>1680</td>\n      <td>0.049600</td>\n    </tr>\n    <tr>\n      <td>1690</td>\n      <td>0.053900</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.044300</td>\n    </tr>\n    <tr>\n      <td>1710</td>\n      <td>0.045000</td>\n    </tr>\n    <tr>\n      <td>1720</td>\n      <td>0.055200</td>\n    </tr>\n    <tr>\n      <td>1730</td>\n      <td>0.043700</td>\n    </tr>\n    <tr>\n      <td>1740</td>\n      <td>0.041600</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.054200</td>\n    </tr>\n    <tr>\n      <td>1760</td>\n      <td>0.050900</td>\n    </tr>\n    <tr>\n      <td>1770</td>\n      <td>0.046000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Training complete!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"model.config.save_pretrained(\"whisper-lora-hindi-final\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T21:54:41.457961Z","iopub.execute_input":"2025-04-14T21:54:41.458263Z","iopub.status.idle":"2025-04-14T21:54:41.464675Z","shell.execute_reply.started":"2025-04-14T21:54:41.458242Z","shell.execute_reply":"2025-04-14T21:54:41.463778Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"!zip -r whisper-lora-hindi-final.zip whisper-lora-hindi-final/\n\n!ls -lh *.zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T21:55:54.643960Z","iopub.execute_input":"2025-04-14T21:55:54.644669Z","iopub.status.idle":"2025-04-14T21:55:55.340117Z","shell.execute_reply.started":"2025-04-14T21:55:54.644643Z","shell.execute_reply":"2025-04-14T21:55:55.338981Z"}},"outputs":[{"name":"stdout","text":"  adding: whisper-lora-hindi-final/ (stored 0%)\n  adding: whisper-lora-hindi-final/special_tokens_map.json (deflated 80%)\n  adding: whisper-lora-hindi-final/config.json (deflated 60%)\n  adding: whisper-lora-hindi-final/normalizer.json (deflated 81%)\n  adding: whisper-lora-hindi-final/merges.txt (deflated 54%)\n  adding: whisper-lora-hindi-final/vocab.json (deflated 69%)\n  adding: whisper-lora-hindi-final/adapter_config.json (deflated 54%)\n  adding: whisper-lora-hindi-final/adapter_model.safetensors (deflated 7%)\n  adding: whisper-lora-hindi-final/preprocessor_config.json (deflated 44%)\n  adding: whisper-lora-hindi-final/added_tokens.json (deflated 80%)\n  adding: whisper-lora-hindi-final/tokenizer_config.json (deflated 96%)\n  adding: whisper-lora-hindi-final/README.md (deflated 66%)\n-rw-r--r-- 1 root root 2.7M Apr 14 21:55 whisper-lora-hindi-final.zip\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('whisper-lora-hindi-final.zip')  # Click to download","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T21:56:46.794171Z","iopub.execute_input":"2025-04-14T21:56:46.794534Z","iopub.status.idle":"2025-04-14T21:56:46.801704Z","shell.execute_reply.started":"2025-04-14T21:56:46.794504Z","shell.execute_reply":"2025-04-14T21:56:46.800902Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/whisper-lora-hindi-final.zip","text/html":"<a href='whisper-lora-hindi-final.zip' target='_blank'>whisper-lora-hindi-final.zip</a><br>"},"metadata":{}}],"execution_count":12}]}