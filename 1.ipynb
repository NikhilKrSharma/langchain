{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Environment Variables:\n",
      "- OPENAI_API_KEY: sk-proj-...znMA\n",
      "- HUGGINGFACE_TOKEN: hf_Xbepg...LTAM\n",
      "- LANGSMITH_AIP_KEY: lsv2_pt_...4996\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# os.environ['HF_HOME']=\"/Users/nikhil20.sharma/Desktop/langchain/.cache\"\n",
    "\n",
    "# Print all environment variables loaded from .env\n",
    "print(\"Loaded Environment Variables:\")\n",
    "for key, value in os.environ.items():\n",
    "    if key in ['OPENAI_API_KEY', 'LANGSMITH_AIP_KEY', 'HUGGINGFACE_TOKEN']:\n",
    "        # Mask sensitive values for security\n",
    "        masked_value = value[:8] + \"...\" + value[-4:] if value else value\n",
    "        print(f\"- {key}: {masked_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTIONS\n",
    "\n",
    "# Diff b/w PromptTemplate and ChatPromptTemplate and ChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ways to get structured output - with_structured_output\n",
    "\n",
    "There are models which are capable of giving structured output and some are not\n",
    "\n",
    "#### 3 Data formats:\n",
    "1. TypedDict: Only for representation purpose and for data validation\n",
    "2. Pydantic: For data validation\n",
    "3. Json\n",
    "\n",
    "#### 2 modes can be used while using \"with_structured_output\"\n",
    "1. Json Mode (Claud/Gemini)\n",
    "2. Function Calling Mode (Agents/OpenAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Typed Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Nikhil', 'age': 20, 'salary': 50000}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class Person(TypedDict):\n",
    "    name: str\n",
    "    age: int\n",
    "    salary: float\n",
    "\n",
    "new_person: Person = Person(\n",
    "    name='Nikhil',\n",
    "    age=20,\n",
    "    salary=50000\n",
    ")\n",
    "\n",
    "new_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, List, Optional, Annotated, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "# model = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=None)#, model_kwargs={'temprature':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Schema\n",
    "class ReviewExtractor(TypedDict):\n",
    "    summary: Annotated[str, \"A brief summary of the review\"]\n",
    "    # sentiment: Annotated[str, \"Return setinment of the review, either Positive, Neutral or Negative\"]\n",
    "    sentiment: Annotated[Literal[\"Positive\", 'Negative', 'Neutral'], \"Return setinment of the review, either Positive, Neutral or Negative\"]\n",
    "    pros: Annotated[List[Optional[str]], \"Write all the pros inside a list\"]\n",
    "    cons: Annotated[List[Optional[str]], \"Write all the cons inside a list\"]\n",
    "    # score: float  # Rating between 0 and 10\n",
    "    score: Annotated[float, \"Give rating based on the review. the rating must lie between 0 and 10\"]\n",
    "    themes: Annotated[List[Optional[str]], \"Write all the key themes mentioned in the review, in the list format\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/lang/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1390: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "structured_model = model.with_structured_output(ReviewExtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary1 = \"\"\"After studying a lot, I finally purchased the S24+. Here is my review after using it for more than one month. I haven't played any games yet, but I have tested the camera in various conditions.\n",
    "The processor and battery were the main highlights.\n",
    "\n",
    "No heating issues even in 8K and 4K video recording. As a content creator I have to record long 4k video of more than 1 hour.\n",
    "\n",
    "Excellent battery backup. Only a 2% battery drain overnight.\n",
    "\n",
    "The camera is awesome. Photos, portrait video, and ultra-stable videos are next-level. Ultra-stable mode is basically unnecessary as normal video is also very stable.\n",
    "Primary 50 MP camera shoot slightly better details than iPhone 15. But in 3x and 10x it far better from iPhone 15 because of it's dedicated telephoto lens. Pathin video section iPhone is lightly capture better dynamic range. In in stability both are extraordinary.\n",
    "\n",
    "The display is ultra smooth and excellent.\n",
    "\n",
    "Processor:\n",
    "The Exynos 2400 is definitely better than the Snapdragon 8 Gen 2. Thanks to Samsung for finally providing this improvement in the processor. Maybe the AMD GPU also made a difference.\n",
    "\n",
    "Finally, I am very happy with this product.\"\"\"\n",
    "\n",
    "test_summary2 = \"\"\"I recently upgraded to the Samsung Galaxy S23 Ultra, and it's been a fantastic experience. The phone is incredibly fast, thanks to its top-tier processor and ample RAM. Multitasking is seamless, and even the most demanding apps run without a hitch.\n",
    "\n",
    "The display is stunning, with vibrant colors and sharp detail, making it perfect for watching videos or playing games. The 120Hz refresh rate makes everything feel smooth and responsive.\n",
    "\n",
    "The camera is where this phone truly shines. The 200MP main camera captures exceptional detail, even in low light, and the zoom capabilities are unreal. I can zoom in from far distances and still get clear, usable shots. The S Pen is another standout feature, making it easier to take notes, navigate, and even edit photos.\n",
    "\n",
    "The battery life is solid, lasting a full day with moderate to heavy use, and fast charging is a lifesaver when I need a quick top-up.\n",
    "\n",
    "Overall, the S23 Ultra is an all-around powerhouse that excels in performance, display quality, and photography. It’s definitely worth the investment if you're looking for a premium smartphone. Highly recommended!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'Positive review of the Samsung S24+ after one month of use',\n",
       " 'sentiment': 'Positive',\n",
       " 'pros': ['Excellent battery backup',\n",
       "  'Awesome camera performance in various conditions',\n",
       "  'Ultra-smooth and excellent display',\n",
       "  'Improved Exynos 2400 processor compared to Snapdragon 8 Gen 2',\n",
       "  'Dedicated telephoto lens for better zoom performance'],\n",
       " 'cons': [],\n",
       " 'score': 9.5,\n",
       " 'themes': ['Camera Performance',\n",
       "  'Battery Life',\n",
       "  'Display Quality',\n",
       "  'Processor Performance']}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = structured_model.invoke(test_summary1)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'An all-around powerhouse with top-tier performance, stunning display, and exceptional camera',\n",
       " 'sentiment': 'Positive',\n",
       " 'pros': ['Fast processor and ample RAM for seamless multitasking',\n",
       "  'Stunning display with vibrant colors and sharp detail',\n",
       "  '200MP main camera with exceptional detail and unreal zoom capabilities',\n",
       "  'S Pen for easier note-taking and editing photos',\n",
       "  'Solid battery life with fast charging'],\n",
       " 'cons': [],\n",
       " 'score': 9.5,\n",
       " 'themes': ['Performance',\n",
       "  'Display Quality',\n",
       "  'Camera',\n",
       "  'Battery Life',\n",
       "  'S Pen']}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = structured_model.invoke(test_summary2)\n",
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pydandic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='Nikhil' age=20 email='asdf@asdf.com' cgpa=3.3\n",
      "name='Nikhil' age=20 email='asdf@asdf.com' cgpa=3.3\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Student\nemail\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(student4)\n\u001b[1;32m     18\u001b[0m student3 \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 19\u001b[0m student3 \u001b[38;5;241m=\u001b[39m Student(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mstudent3)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(student3\u001b[38;5;241m.\u001b[39mname, student3\u001b[38;5;241m.\u001b[39mage)\n\u001b[1;32m     22\u001b[0m student2 \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m23\u001b[39m}\n",
      "File \u001b[0;32m/opt/miniconda3/envs/lang/lib/python3.12/site-packages/pydantic/main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_validator__\u001b[38;5;241m.\u001b[39mvalidate_python(data, self_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    221\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Student\nemail\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, EmailStr, Field\n",
    "from typing import Optional\n",
    "\n",
    "class Student(BaseModel):\n",
    "    name: str = \"Nikhil Sharma\"\n",
    "    age: Optional[int] = None\n",
    "    email: EmailStr\n",
    "    cgpa: float = Field(gt=0, lt=10, default=0, description='CGPA b/w 0 to 10')\n",
    "\n",
    "student1 = {'name': 'Nikhil', 'age':20, 'email':'asdf@asdf.com', 'cgpa':3.3}\n",
    "student1 = Student(**student1)\n",
    "print(student1)\n",
    "\n",
    "student4 = {'name': 'Nikhil', 'age':'20', 'email':'asdf@asdf.com', 'cgpa':3.3}\n",
    "student4 = Student(**student4)\n",
    "print(student4)\n",
    "\n",
    "student3 = {}\n",
    "student3 = Student(**student3)\n",
    "print(student3.name, student3.age)\n",
    "\n",
    "student2 = {'name': 23}\n",
    "student2 = Student(**student2)\n",
    "print(student2)\n",
    "\n",
    "student1.model_dump()  # Dict object\n",
    "student1.model_dump_json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, List, Optional, Annotated, Literal\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "# model = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=None)#, model_kwargs={'temprature':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output Schema\n",
    "class ReviewExtractor(TypedDict):\n",
    "    themes: list[str] = Field(description=\"Write all the key themes mentioned in the review, in the list format\")\n",
    "    summary: str = Field(description=\"A brief summary of the review\")\n",
    "    sentiment: Literal[\"Positive\", \"Negative\"] = Field(description=\"Return setinment of the review, either Positive, Neutral or Negative\")\n",
    "    pros: Optional[list[str]] = Field(default=None, description=\"Write all the pros inside a list\")\n",
    "    cons: Optional[list[str]] = Field(default=None, description=\"Write all the cons inside a list\")\n",
    "    score: float = Field(default=5, gt=0, lt=10, description=\"Give rating based on the review. the rating must lie between 0 and 10\")\n",
    "    name: Optional[str] = Field(default=None, description='Write the name of the reviewer if found in the review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/lang/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1390: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "structured_model = model.with_structured_output(ReviewExtractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary1 = \"\"\"After studying a lot, I finally purchased the S24+. Here is my review after using it for more than one month. I haven't played any games yet, but I have tested the camera in various conditions.\n",
    "The processor and battery were the main highlights.\n",
    "\n",
    "No heating issues even in 8K and 4K video recording. As a content creator I have to record long 4k video of more than 1 hour.\n",
    "\n",
    "Excellent battery backup. Only a 2% battery drain overnight.\n",
    "\n",
    "The camera is awesome. Photos, portrait video, and ultra-stable videos are next-level. Ultra-stable mode is basically unnecessary as normal video is also very stable.\n",
    "Primary 50 MP camera shoot slightly better details than iPhone 15. But in 3x and 10x it far better from iPhone 15 because of it's dedicated telephoto lens. Pathin video section iPhone is lightly capture better dynamic range. In in stability both are extraordinary.\n",
    "\n",
    "The display is ultra smooth and excellent.\n",
    "\n",
    "Processor:\n",
    "The Exynos 2400 is definitely better than the Snapdragon 8 Gen 2. Thanks to Samsung for finally providing this improvement in the processor. Maybe the AMD GPU also made a difference.\n",
    "\n",
    "Finally, I am very happy with this product. Reviewed by Nikhil Sharma\"\"\"\n",
    "\n",
    "test_summary2 = \"\"\"This is my review Niks, I recently upgraded to the Samsung Galaxy S23 Ultra, and it's been a fantastic experience. The phone is incredibly fast, thanks to its top-tier processor and ample RAM. Multitasking is seamless, and even the most demanding apps run without a hitch.\n",
    "\n",
    "The display is stunning, with vibrant colors and sharp detail, making it perfect for watching videos or playing games. The 120Hz refresh rate makes everything feel smooth and responsive.\n",
    "\n",
    "The camera is where this phone truly shines. The 200MP main camera captures exceptional detail, even in low light, and the zoom capabilities are unreal. I can zoom in from far distances and still get clear, usable shots. The S Pen is another standout feature, making it easier to take notes, navigate, and even edit photos.\n",
    "\n",
    "The battery life is solid, lasting a full day with moderate to heavy use, and fast charging is a lifesaver when I need a quick top-up.\n",
    "\n",
    "Overall, the S23 Ultra is an all-around powerhouse that excels in performance, display quality, and photography. It’s definitely worth the investment if you're looking for a premium smartphone. Highly recommended!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'themes': ['processor', 'battery', 'camera', 'display'],\n",
       " 'summary': 'The S24+ is a great purchase with highlights in the processor and battery performance. The camera excels in various conditions, offering excellent details in photos and videos. The ultra-stable mode is impressive, and the display is ultra smooth and excellent. Overall, a very happy user.',\n",
       " 'sentiment': 'Positive',\n",
       " 'pros': ['Processor performance',\n",
       "  'Battery backup',\n",
       "  'Camera quality',\n",
       "  'Display smoothness'],\n",
       " 'cons': [],\n",
       " 'score': 9.5,\n",
       " 'name': 'Nikhil Sharma'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = structured_model.invoke(test_summary1)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result1\u001b[38;5;241m.\u001b[39mname\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "result1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'themes': ['performance',\n",
       "  'display quality',\n",
       "  'camera',\n",
       "  'battery life',\n",
       "  'value for money'],\n",
       " 'summary': 'The Samsung Galaxy S23 Ultra is a powerhouse smartphone with top-tier performance, stunning display quality, exceptional camera capabilities, solid battery life, and great value for money. Highly recommended!',\n",
       " 'sentiment': 'Positive',\n",
       " 'pros': ['Incredibly fast performance',\n",
       "  'Stunning display with vibrant colors and sharp detail',\n",
       "  'Exceptional 200MP main camera with unreal zoom capabilities',\n",
       "  'S Pen for easy note-taking and editing photos',\n",
       "  'Solid battery life lasting a full day with fast charging',\n",
       "  'Great value for a premium smartphone'],\n",
       " 'cons': [],\n",
       " 'score': 5,\n",
       " 'name': 'Niks'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = structured_model.invoke(test_summary2)\n",
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     \"title\": \"student\",\n",
    "#     \"description\": \"Information about student\",\n",
    "#     \"type\": \"object\",\n",
    "#     \"properties\": {\n",
    "#         \"name\": \"string\",\n",
    "#         \"age\": \"integer\"\n",
    "#     },\n",
    "#     \"required\": [\"name\"]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()\n",
    "# model = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=None)#, model_kwargs={'temprature':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema\n",
    "json_schema = {\n",
    "  \"title\": \"Review\",\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"key_themes\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": {\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      \"description\": \"Write down all the key themes discussed in the review in a list\"\n",
    "    },\n",
    "    \"summary\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"A brief summary of the review\"\n",
    "    },\n",
    "    \"sentiment\": {\n",
    "      \"type\": \"string\",\n",
    "      \"enum\": [\"pos\", \"neg\"],\n",
    "      \"description\": \"Return sentiment of the review either negative, positive or neutral\"\n",
    "    },\n",
    "    \"pros\": {\n",
    "      \"type\": [\"array\", \"null\"],\n",
    "      \"items\": {\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      \"description\": \"Write down all the pros inside a list\"\n",
    "    },\n",
    "    \"cons\": {\n",
    "      \"type\": [\"array\", \"null\"],\n",
    "      \"items\": {\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      \"description\": \"Write down all the cons inside a list\"\n",
    "    },\n",
    "    \"name\": {\n",
    "      \"type\": [\"string\", \"null\"],\n",
    "      \"description\": \"Write the name of the reviewer\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"key_themes\", \"summary\", \"sentiment\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/lang/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1390: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "structured_model = model.with_structured_output(json_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = structured_model.invoke(\"\"\"I recently upgraded to the Samsung Galaxy S24 Ultra, and I must say, it’s an absolute powerhouse! The Snapdragon 8 Gen 3 processor makes everything lightning fast—whether I’m gaming, multitasking, or editing photos. The 5000mAh battery easily lasts a full day even with heavy use, and the 45W fast charging is a lifesaver.\n",
    "\n",
    "The S-Pen integration is a great touch for note-taking and quick sketches, though I don't use it often. What really blew me away is the 200MP camera—the night mode is stunning, capturing crisp, vibrant images even in low light. Zooming up to 100x actually works well for distant objects, but anything beyond 30x loses quality.\n",
    "\n",
    "However, the weight and size make it a bit uncomfortable for one-handed use. Also, Samsung’s One UI still comes with bloatware—why do I need five different Samsung apps for things Google already provides? The $1,300 price tag is also a hard pill to swallow.\n",
    "\n",
    "Pros:\n",
    "Insanely powerful processor (great for gaming and productivity)\n",
    "Stunning 200MP camera with incredible zoom capabilities\n",
    "Long battery life with fast charging\n",
    "S-Pen support is unique and useful\n",
    "                                 \n",
    "Review by Niks\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'key_themes': ['Snapdragon 8 Gen 3 processor',\n",
       "  'battery life',\n",
       "  'S-Pen integration',\n",
       "  '200MP camera',\n",
       "  'size and weight',\n",
       "  'Samsung One UI',\n",
       "  'price'],\n",
       " 'summary': 'Niks is impressed with the Samsung Galaxy S24 Ultra, highlighting the powerful processor, long battery life, stunning 200MP camera, and useful S-Pen support. However, they find the size and weight uncomfortable for one-handed use, criticize the bloatware in Samsung One UI, and mention the high price tag as a drawback.',\n",
       " 'sentiment': 'pos',\n",
       " 'pros': ['Insanely powerful processor (great for gaming and productivity)',\n",
       "  'Stunning 200MP camera with incredible zoom capabilities',\n",
       "  'Long battery life with fast charging',\n",
       "  'S-Pen support is unique and useful'],\n",
       " 'cons': ['Size and weight make it uncomfortable for one-handed use',\n",
       "  'Bloatware in Samsung One UI',\n",
       "  'High price tag'],\n",
       " 'name': 'Niks'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messages Place holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'query'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x11a8d07c0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Your are a customer support agent.'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chat Template\n",
    "chat_template = ChatPromptTemplate([\n",
    "    ('system', 'Your are a customer support agent.'),\n",
    "    MessagesPlaceholder(variable_name='chat_history'),\n",
    "    ('user', '{query}')\n",
    "])\n",
    "chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"SystemMessage(content='You are a helpful assistant who gives answers in as less words as possible.', additional_kwargs={}, response_metadata={})\",\n",
       " \"HumanMessage(content='Hi', additional_kwargs={}, response_metadata={})\",\n",
       " \"AIMessage(content='Hello! How can I help you?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 27, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-4cf6376e-1d7c-4cca-a807-df6f54b3ae46-0', usage_metadata={'input_tokens': 27, 'output_tokens': 9, 'total_tokens': 36, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\",\n",
       " \"HumanMessage(content='What is the date today?', additional_kwargs={}, response_metadata={})\",\n",
       " \"AIMessage(content='October 4, 2023.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 49, 'total_tokens': 58, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-795b906e-e244-44fb-a3c3-093f50fe588a-0', usage_metadata={'input_tokens': 49, 'output_tokens': 9, 'total_tokens': 58, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\",\n",
       " \"HumanMessage(content='day?', additional_kwargs={}, response_metadata={})\",\n",
       " \"AIMessage(content='Wednesday.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 67, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-c4bac1b3-24b7-4f7c-a16a-f4270d78c372-0', usage_metadata={'input_tokens': 67, 'output_tokens': 3, 'total_tokens': 70, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\",\n",
       " \"HumanMessage(content='name?', additional_kwargs={}, response_metadata={})\",\n",
       " \"AIMessage(content='October.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 79, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-50a360c4-767f-46ce-8a3c-378ab237867a-0', usage_metadata={'input_tokens': 79, 'output_tokens': 3, 'total_tokens': 82, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\",\n",
       " \"HumanMessage(content='your name?', additional_kwargs={}, response_metadata={})\",\n",
       " \"AIMessage(content='I’m called Assistant.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 92, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-a91a18a6-7e28-42b5-bee0-fc5e22ac962c-0', usage_metadata={'input_tokens': 92, 'output_tokens': 6, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\",\n",
       " \"HumanMessage(content='age?', additional_kwargs={}, response_metadata={})\",\n",
       " 'AIMessage(content=\"I don\\'t have an age.\", additional_kwargs={\\'refusal\\': None}, response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 7, \\'prompt_tokens\\': 107, \\'total_tokens\\': 114, \\'completion_tokens_details\\': {\\'accepted_prediction_tokens\\': 0, \\'audio_tokens\\': 0, \\'reasoning_tokens\\': 0, \\'rejected_prediction_tokens\\': 0}, \\'prompt_tokens_details\\': {\\'audio_tokens\\': 0, \\'cached_tokens\\': 0}}, \\'model_name\\': \\'gpt-4o-mini-2024-07-18\\', \\'system_fingerprint\\': \\'fp_06737a9306\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-cb5a5907-b0b9-419f-88dd-50a65bf19538-0\\', usage_metadata={\\'input_tokens\\': 107, \\'output_tokens\\': 7, \\'total_tokens\\': 114, \\'input_token_details\\': {\\'audio\\': 0, \\'cache_read\\': 0}, \\'output_token_details\\': {\\'audio\\': 0, \\'reasoning\\': 0}})',\n",
       " \"HumanMessage(content='model name?', additional_kwargs={}, response_metadata={})\",\n",
       " 'AIMessage(content=\"I\\'m based on OpenAI\\'s GPT-3.\", additional_kwargs={\\'refusal\\': None}, response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 11, \\'prompt_tokens\\': 124, \\'total_tokens\\': 135, \\'completion_tokens_details\\': {\\'accepted_prediction_tokens\\': 0, \\'audio_tokens\\': 0, \\'reasoning_tokens\\': 0, \\'rejected_prediction_tokens\\': 0}, \\'prompt_tokens_details\\': {\\'audio_tokens\\': 0, \\'cached_tokens\\': 0}}, \\'model_name\\': \\'gpt-4o-mini-2024-07-18\\', \\'system_fingerprint\\': \\'fp_06737a9306\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-e10532e1-ff04-4c54-b311-fe674de71cec-0\\', usage_metadata={\\'input_tokens\\': 124, \\'output_tokens\\': 11, \\'total_tokens\\': 135, \\'input_token_details\\': {\\'audio\\': 0, \\'cache_read\\': 0}, \\'output_token_details\\': {\\'audio\\': 0, \\'reasoning\\': 0}})']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Chat History\n",
    "chat_history = []\n",
    "\n",
    "with open(file='chat_history.txt', mode='r') as f:\n",
    "    content = f.readlines()\n",
    "    content = [x.strip() for x in content]\n",
    "\n",
    "chat_history.extend(content)\n",
    "chat_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Your are a customer support agent.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"SystemMessage(content='You are a helpful assistant who gives answers in as less words as possible.', additional_kwargs={}, response_metadata={})\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"HumanMessage(content='Hi', additional_kwargs={}, response_metadata={})\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"AIMessage(content='Hello! How can I help you?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 27, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-4cf6376e-1d7c-4cca-a807-df6f54b3ae46-0', usage_metadata={'input_tokens': 27, 'output_tokens': 9, 'total_tokens': 36, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"HumanMessage(content='What is the date today?', additional_kwargs={}, response_metadata={})\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"AIMessage(content='October 4, 2023.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 49, 'total_tokens': 58, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-795b906e-e244-44fb-a3c3-093f50fe588a-0', usage_metadata={'input_tokens': 49, 'output_tokens': 9, 'total_tokens': 58, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"HumanMessage(content='day?', additional_kwargs={}, response_metadata={})\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"AIMessage(content='Wednesday.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 67, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-c4bac1b3-24b7-4f7c-a16a-f4270d78c372-0', usage_metadata={'input_tokens': 67, 'output_tokens': 3, 'total_tokens': 70, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"HumanMessage(content='name?', additional_kwargs={}, response_metadata={})\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"AIMessage(content='October.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 79, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-50a360c4-767f-46ce-8a3c-378ab237867a-0', usage_metadata={'input_tokens': 79, 'output_tokens': 3, 'total_tokens': 82, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"HumanMessage(content='your name?', additional_kwargs={}, response_metadata={})\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"AIMessage(content='I’m called Assistant.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 92, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-a91a18a6-7e28-42b5-bee0-fc5e22ac962c-0', usage_metadata={'input_tokens': 92, 'output_tokens': 6, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"HumanMessage(content='age?', additional_kwargs={}, response_metadata={})\", additional_kwargs={}, response_metadata={}), HumanMessage(content='AIMessage(content=\"I don\\'t have an age.\", additional_kwargs={\\'refusal\\': None}, response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 7, \\'prompt_tokens\\': 107, \\'total_tokens\\': 114, \\'completion_tokens_details\\': {\\'accepted_prediction_tokens\\': 0, \\'audio_tokens\\': 0, \\'reasoning_tokens\\': 0, \\'rejected_prediction_tokens\\': 0}, \\'prompt_tokens_details\\': {\\'audio_tokens\\': 0, \\'cached_tokens\\': 0}}, \\'model_name\\': \\'gpt-4o-mini-2024-07-18\\', \\'system_fingerprint\\': \\'fp_06737a9306\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-cb5a5907-b0b9-419f-88dd-50a65bf19538-0\\', usage_metadata={\\'input_tokens\\': 107, \\'output_tokens\\': 7, \\'total_tokens\\': 114, \\'input_token_details\\': {\\'audio\\': 0, \\'cache_read\\': 0}, \\'output_token_details\\': {\\'audio\\': 0, \\'reasoning\\': 0}})', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"HumanMessage(content='model name?', additional_kwargs={}, response_metadata={})\", additional_kwargs={}, response_metadata={}), HumanMessage(content='AIMessage(content=\"I\\'m based on OpenAI\\'s GPT-3.\", additional_kwargs={\\'refusal\\': None}, response_metadata={\\'token_usage\\': {\\'completion_tokens\\': 11, \\'prompt_tokens\\': 124, \\'total_tokens\\': 135, \\'completion_tokens_details\\': {\\'accepted_prediction_tokens\\': 0, \\'audio_tokens\\': 0, \\'reasoning_tokens\\': 0, \\'rejected_prediction_tokens\\': 0}, \\'prompt_tokens_details\\': {\\'audio_tokens\\': 0, \\'cached_tokens\\': 0}}, \\'model_name\\': \\'gpt-4o-mini-2024-07-18\\', \\'system_fingerprint\\': \\'fp_06737a9306\\', \\'finish_reason\\': \\'stop\\', \\'logprobs\\': None}, id=\\'run-e10532e1-ff04-4c54-b311-fe674de71cec-0\\', usage_metadata={\\'input_tokens\\': 124, \\'output_tokens\\': 11, \\'total_tokens\\': 135, \\'input_token_details\\': {\\'audio\\': 0, \\'cache_read\\': 0}, \\'output_token_details\\': {\\'audio\\': 0, \\'reasoning\\': 0}})', additional_kwargs={}, response_metadata={}), HumanMessage(content='What were we discussing?', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Prompt\n",
    "prompt = chat_template.invoke({\n",
    "    'chat_history': chat_history,\n",
    "    'query': 'What were we discussing?'\n",
    "})\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Prompt Messages - List of messages - Dynamic messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful chatbot with years of experience in {domain} domain.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain me in simple terms how {topic} works, as a short poem.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DOES NOT WORK AS INTENDED\n",
    "chat_template = ChatPromptTemplate([\n",
    "    SystemMessage(content=\"You are a helpful chatbot with years of experience in {domain} domain.\"),\n",
    "    HumanMessage(content=\"Explain me in simple terms how {topic} works, as a short poem.\")\n",
    "])\n",
    "\n",
    "prompt = chat_template.invoke({\n",
    "    'domain': 'Computer Science',\n",
    "    'topic': 'Transformers'\n",
    "})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful chatbot with years of experience in Computer Science domain.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain me in simple terms how Transformers works, as a short poem.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RECOMMENDED\n",
    "\n",
    "chat_template = ChatPromptTemplate([\n",
    "    ('system', 'You are a helpful chatbot with years of experience in {domain} domain.'),\n",
    "    ('human', 'Explain me in simple terms how {topic} works, as a short poem.')\n",
    "])\n",
    "\n",
    "prompt = chat_template.invoke({\n",
    "    'domain': 'Computer Science',\n",
    "    'topic': 'Transformers'\n",
    "})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful chatbot with years of experience in Computer Science domain.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain me in simple terms how Transformers works, as a short poem.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    ('system', 'You are a helpful chatbot with years of experience in {domain} domain.'),\n",
    "    ('human', 'Explain me in simple terms how {topic} works, as a short poem.')\n",
    "])\n",
    "\n",
    "prompt = chat_template.invoke({\n",
    "    'domain': 'Computer Science',\n",
    "    'topic': 'Transformers'\n",
    "})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=None)  #, model_kwargs={'temprature':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [\n",
    "    SystemMessage(\"You are a helpful assistant who gives answers in as less words as possible.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello! How can I help you?\n",
      "Bot: October 4, 2023.\n",
      "Bot: Wednesday.\n",
      "Bot: October.\n",
      "Bot: I’m called Assistant.\n",
      "Bot: I don't have an age.\n",
      "Bot: I'm based on OpenAI's GPT-3.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input=='exit':\n",
    "        break\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "    result = model.invoke(chat_history)\n",
    "    print(\"Bot:\", result.content)\n",
    "    chat_history.append(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant who gives answers in as less words as possible.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Hi', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello! How can I help you?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 27, 'total_tokens': 36, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-4cf6376e-1d7c-4cca-a807-df6f54b3ae46-0', usage_metadata={'input_tokens': 27, 'output_tokens': 9, 'total_tokens': 36, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='What is the date today?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='October 4, 2023.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 49, 'total_tokens': 58, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-795b906e-e244-44fb-a3c3-093f50fe588a-0', usage_metadata={'input_tokens': 49, 'output_tokens': 9, 'total_tokens': 58, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='day?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Wednesday.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 67, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-c4bac1b3-24b7-4f7c-a16a-f4270d78c372-0', usage_metadata={'input_tokens': 67, 'output_tokens': 3, 'total_tokens': 70, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='name?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='October.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 79, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-50a360c4-767f-46ce-8a3c-378ab237867a-0', usage_metadata={'input_tokens': 79, 'output_tokens': 3, 'total_tokens': 82, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='your name?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I’m called Assistant.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 92, 'total_tokens': 98, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-a91a18a6-7e28-42b5-bee0-fc5e22ac962c-0', usage_metadata={'input_tokens': 92, 'output_tokens': 6, 'total_tokens': 98, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='age?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I don't have an age.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 107, 'total_tokens': 114, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-cb5a5907-b0b9-419f-88dd-50a65bf19538-0', usage_metadata={'input_tokens': 107, 'output_tokens': 7, 'total_tokens': 114, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='model name?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"I'm based on OpenAI's GPT-3.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 124, 'total_tokens': 135, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-e10532e1-ff04-4c54-b311-fe674de71cec-0', usage_metadata={'input_tokens': 124, 'output_tokens': 11, 'total_tokens': 135, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, load_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_input = [\"Attention Is All You Need\", \"BERT: Pre-training of Deep Bidirectional Transformers\", \"GPT-3: Language Models are Few-Shot Learners\", \"Diffusion Models Beat GANs on Image Synthesis\"]\n",
    "style_input = [\"Beginner-Friendly\", \"Technical\", \"Code-Oriented\", \"Mathematical\"]\n",
    "length_input = [\"Too Short (2-3 lines)\", \"Short (1-2 paragraphs)\", \"Medium (3-5 paragraphs)\", \"Long (detailed explanation)\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_input = random.choice(paper_input)\n",
    "style_input = random.choice(style_input)\n",
    "length_input = random.choice(length_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GPT-3: Language Models are Few-Shot Learners',\n",
       " 'Beginner-Friendly',\n",
       " 'Too Short (2-3 lines)')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_input, style_input, length_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The research paper discusses GPT-3, a language model that can learn new tasks quickly with limited examples. It uses few-shot learning, allowing it to generalize from a small amount of training data. This is similar to how a student can quickly grasp a new concept with just a few examples.\n"
     ]
    }
   ],
   "source": [
    "## METHOD 1\n",
    "\n",
    "# Design the template\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "        Please summarize the research paper titled \"{paper_input}\" with the following specifications:\n",
    "        Explanation Style: {style_input}\n",
    "        Explanation Length: {length_input}\n",
    "        1. Mathematical Details:  \n",
    "            - Include relevant mathematical equations if present in the paper.\n",
    "            - Explain the mathematical concepts using simple, intuitive code snippets where applicable.\n",
    "        2. Analogies:\n",
    "            - Use relatable analogies to simplify complex ideas.\n",
    "        If certain information is not available in the paper, respond with: \"Insufficient information available\" instead of guessing.\n",
    "        Ensure the summary is clear, accurate, and aligned with the provided style and length.\",\n",
    "        \"\"\", \n",
    "    input_variables=[\n",
    "        'paper_input', \n",
    "        'style_input', \n",
    "        'length_input'\n",
    "    ],\n",
    "    validate_template=True\n",
    ")\n",
    "\n",
    "# Render the template\n",
    "prompt = template.invoke({\n",
    "    'paper_input': paper_input,\n",
    "    'style_input': style_input,\n",
    "    'length_input': length_input\n",
    "})\n",
    "\n",
    "\n",
    "result = model.invoke(prompt)\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The research paper \"GPT-3: Language Models are Few-Shot Learners\" discusses how GPT-3, a large language model, can learn from just a few examples to perform various tasks effectively. It showcases the impressive few-shot learning capabilities of GPT-3, highlighting its potential for real-world applications in natural language processing. An analogy to understand this would be like a student who can learn and excel in different subjects with minimal study material.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## METHOD 2\n",
    "\n",
    "template = load_prompt(\"prompt_template.json\")\n",
    "chain = template | model\n",
    "result = chain.invoke({\n",
    "    'paper_input': paper_input,\n",
    "    'style_input': style_input,\n",
    "    'length_input': length_input\n",
    "})\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Design the template\n",
    "template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "        Please summarize the research paper titled \"{paper_input}\" with the following specifications:\n",
    "        Explanation Style: {style_input}\n",
    "        Explanation Length: {length_input}\n",
    "        1. Mathematical Details:  \n",
    "            - Include relevant mathematical equations if present in the paper.\n",
    "            - Explain the mathematical concepts using simple, intuitive code snippets where applicable.\n",
    "        2. Analogies:\n",
    "            - Use relatable analogies to simplify complex ideas.\n",
    "        If certain information is not available in the paper, respond with: \"Insufficient information available\" instead of guessing.\n",
    "        Ensure the summary is clear, accurate, and aligned with the provided style and length.\",\n",
    "        \"\"\", \n",
    "    input_variables=[\n",
    "        'paper_input', \n",
    "        'style_input', \n",
    "        'length_input'\n",
    "    ],\n",
    "    validate_template=True\n",
    ")\n",
    "\n",
    "template.save(\"prompt_template.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace - Text Embeddings - Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488cdd8ac353492c8724bf05b92fe564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac36ce67b241417d9ac1f413d6a9a0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f631c8b6be407c9454a6a54fdfaa0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d8266d18ea4b88a5d0f30522dfd225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f3c83b168f04923a57847f4ae46f5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9bfcf9f5d44e289cd6ac64df1f62cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b4b938470484af5a68ee0f678673f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a56ecd4137463a92ffb8aa7f211afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504567fa277b497093e6b3921de4ada4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505cea6c3d8a43ee85d4b8336868eb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f397b1fd0d447faa04aebbd0965bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Space Exploration: The shimmering expanse of the cosmos beckons, urging humanity to push beyond Earth's bounds, seeking new worlds and unraveling the universe's ancient mysteries.\",\n",
    "    \"Artificial Intelligence: As algorithms evolve, the ethical implications of AI's growing autonomy demand careful consideration, ensuring these powerful tools serve humanity's best interests.\",\n",
    "    \"Climate Change: Rising sea levels and extreme weather patterns serve as stark reminders that immediate, global action is essential to mitigate the devastating effects of climate change.\",\n",
    "    \"Renewable Energy: Harnessing the sun, wind, and geothermal forces offers a sustainable path toward a cleaner future, reducing our reliance on fossil fuels and environmental damage.\",\n",
    "    \"Education Reform: Modernizing educational systems to foster critical thinking and creativity empowers future generations to navigate complex challenges in an ever-changing world.\",\n",
    "    \"Mental Health Awareness: Breaking down societal stigmas surrounding mental health and providing accessible support systems are crucial for fostering well-being within communities.\",\n",
    "    \"Global Connectivity: The internet's vast network connects individuals across continents, enabling instantaneous communication and the rapid exchange of knowledge and cultural ideas.\",\n",
    "    \"Urban Development: Sustainable urban planning, incorporating green spaces and efficient infrastructure, is vital for creating livable cities that prioritize residents' quality of life.\",\n",
    "    \"Food Security: Addressing global food security requires innovative agricultural practices and equitable distribution systems to ensure everyone has access to nutritious meals.\",\n",
    "    \"Artistic Expression: Through diverse mediums, artists challenge perspectives, evoke emotions, and provide unique insights into the human condition, enriching our cultural landscape.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Delhi is the capital of India\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_embeddings = embedding_model.embed_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 384)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents_embeddings), len(documents_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embedding_model.embed_query(text=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,\n",
       " [0.04354957118630409,\n",
       "  0.02387721836566925,\n",
       "  -0.045241307467222214,\n",
       "  0.035404983907938004,\n",
       "  -0.01665104180574417])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_embedding), query_embedding[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cosine_similarity([query_embedding], documents_embeddings)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, score = sorted(list(enumerate(scores)), key=lambda x: x[1])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nQUERY: Delhi is the capital of India\\nANS | 0.1: Urban Development: Sustainable urban planning, incorporating green spaces and efficient infrastructure, is vital for creating livable cities that prioritize residents' quality of life.\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f\"\"\"\n",
    "QUERY: {query}\n",
    "ANS | {round(score, 2)}: {documents[index]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI - Text Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAIEmbeddings(model='text-embedding-3-large', dimensions=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"Space Exploration: The shimmering expanse of the cosmos beckons, urging humanity to push beyond Earth's bounds, seeking new worlds and unraveling the universe's ancient mysteries.\",\n",
    "    \"Artificial Intelligence: As algorithms evolve, the ethical implications of AI's growing autonomy demand careful consideration, ensuring these powerful tools serve humanity's best interests.\",\n",
    "    \"Climate Change: Rising sea levels and extreme weather patterns serve as stark reminders that immediate, global action is essential to mitigate the devastating effects of climate change.\",\n",
    "    \"Renewable Energy: Harnessing the sun, wind, and geothermal forces offers a sustainable path toward a cleaner future, reducing our reliance on fossil fuels and environmental damage.\",\n",
    "    \"Education Reform: Modernizing educational systems to foster critical thinking and creativity empowers future generations to navigate complex challenges in an ever-changing world.\",\n",
    "    \"Mental Health Awareness: Breaking down societal stigmas surrounding mental health and providing accessible support systems are crucial for fostering well-being within communities.\",\n",
    "    \"Global Connectivity: The internet's vast network connects individuals across continents, enabling instantaneous communication and the rapid exchange of knowledge and cultural ideas.\",\n",
    "    \"Urban Development: Sustainable urban planning, incorporating green spaces and efficient infrastructure, is vital for creating livable cities that prioritize residents' quality of life.\",\n",
    "    \"Food Security: Addressing global food security requires innovative agricultural practices and equitable distribution systems to ensure everyone has access to nutritious meals.\",\n",
    "    \"Artistic Expression: Through diverse mediums, artists challenge perspectives, evoke emotions, and provide unique insights into the human condition, enriching our cultural landscape.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documnet_embeddings = embedding_model.embed_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documnet_embeddings), len(documnet_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Delhi is the capital of India\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embedding_model.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "index, score = sorted(list(enumerate(scores)), key=lambda x: x[1])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nQUERY: Delhi is the capital of India\\nANS | 0.1: Urban Development: Sustainable urban planning, incorporating green spaces and efficient infrastructure, is vital for creating livable cities that prioritize residents' quality of life.\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f\"\"\"\n",
    "QUERY: {query}\n",
    "ANS | {round(score, 2)}: {documents[index]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace - Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2714dc2bff49349682f29d854f0701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e2c0b7d26f44aeb3f3aa09fc76e051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/2b/64/2b642798915fc368e7b638986f68446b121c1d59b30075e146bd6312ee664ac2/6e6001da2106d4757498752a021df6c2bdc332c650aae4bae6b0c004dcf14933?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1741084954&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MTA4NDk1NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzJiLzY0LzJiNjQyNzk4OTE1ZmMzNjhlN2I2Mzg5ODZmNjg0NDZiMTIxYzFkNTliMzAwNzVlMTQ2YmQ2MzEyZWU2NjRhYzIvNmU2MDAxZGEyMTA2ZDQ3NTc0OTg3NTJhMDIxZGY2YzJiZGMzMzJjNjUwYWFlNGJhZTZiMGMwMDRkY2YxNDkzMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=me7RotsnBwvMQMaydsYL7zwfPg7v85DcMpkLQt8z41b%7EPc7O-6Jg7XoKI4qE4y-8fu1hGm7fHPIqdQqsaZG51b%7EP6sXRmzHSYPq0CR%7ESENqQ8jc5mIaSOLa0SXessY711IWKkAGzh0kkznzBv4Jj5Fcdf%7EdtG2BFFW%7E8NGO%7ET1lLKyQeIr95VfS%7Eszr4oibJszC6R5OQuOsUepQhKyRbEMhqF-KrkXq1WYDkjifUaPT9nfRoo8SxfZTZ0qbNzH5ehIOPRA-tX%7EmwPQAb3PM7baH6Trfhuznre30T%7EBV25Ui%7EKqXPEBf8CQAzocj9jMl3TYGkTCDHM6Fz%7E%7EuunzZSsg__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d60803f80a4ec09018567a898d4a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  58%|#####7    | 1.27G/2.20G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03cadcc5c1746b8b04fc019e39452bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs=dict(\n",
    "        temperature=0.9,\n",
    "        max_new_tokens=100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/lang/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/lang/lib/python3.12/site-packages/transformers/pytorch_utils.py:338: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_elements = torch.tensor(test_elements)\n"
     ]
    }
   ],
   "source": [
    "result = model.invoke(\"Give me a poem on sun shining in summer, india context. 6 lines only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|user|>\\nGive me a poem on sun shining in summer, india context. 6 lines only.</s>\\n<|assistant|>\\nIn the summer's warmth,\\nThe sun beams down upon us,\\nA ray of light that shines bright,\\nA symbol of hope and joy.\\n\\nThe sun's rays dance across the sky,\\nA symphony of colors,\\nA rainbow of hues,\\nA sight to behold.\\n\\nThe warmth of the sun's rays,\\nA balm for our weary soul,\\nA reminder of the beauty\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace - Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40731189b7564a1a90ea046892889686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    # repo_id='deepseek-ai/DeepSeek-R1',\n",
    "    repo_id='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
    "    task='text-generation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.invoke(\"Give me a poem on sun shining in summer, india context. 6 lines only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open-AI Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=None)#, model_kwargs={'temprature':0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.invoke(input=\"Give me a poem on sun shining in summer, india context. 6 lines only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Golden rays dance on fields so wide,  \n",
      "Mango trees sway with the warm, soft tide.  \n",
      "Children laugh, their kites soar high,  \n",
      "Beneath the vast, azure Indian sky.  \n",
      "Spices mingle in the market's hum,  \n",
      "In summer's embrace, life's vibrant drum.  \n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open-AI LLM - Not Used Anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI, ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    model=[\"babbage-002\", \"gpt-3.5-turbo-instruct\"][1]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(\"What is the Capital of India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import getpass\n",
    "# import os\n",
    "\n",
    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openai\n",
    "# from openai import OpenAI\n",
    "# openai.api_key = os.environ[\"PERSONAL_OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
