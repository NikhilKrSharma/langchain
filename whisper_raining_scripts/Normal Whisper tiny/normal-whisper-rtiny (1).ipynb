{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11304011,"sourceType":"datasetVersion","datasetId":7069361}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install jiwer\n\nimport torch\nimport torchaudio\nfrom datasets import load_dataset, Audio\nfrom transformers import WhisperProcessor, WhisperForConditionalGeneration\nfrom jiwer import wer, cer\n\ndataset_path = \"/kaggle/input/testing/train-00000-of-00010.parquet\"\ndataset = load_dataset(\"parquet\", data_files=dataset_path)[\"train\"]\n\nmodel_name = \"openai/whisper-tiny\"\nprocessor = WhisperProcessor.from_pretrained(model_name)\nmodel = WhisperForConditionalGeneration.from_pretrained(model_name)\n\nprocessor.tokenizer.language = \"hi\"\nprocessor.tokenizer.set_prefix_tokens = lambda *args, **kwargs: []\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\ndataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n\ndef transcribe(batch):\n    inputs = processor(batch[\"audio\"][\"array\"], sampling_rate=16000, return_tensors=\"pt\")\n    input_features = inputs.input_features.to(device)\n\n    forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"hi\", task=\"transcribe\")\n    predicted_ids = model.generate(input_features, forced_decoder_ids=forced_decoder_ids)\n    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n    batch[\"prediction\"] = transcription\n    return batch\n\nresult = dataset.map(transcribe)\n\nreferences = result[\"text\"]\npredictions = result[\"prediction\"]\n\nwer_score = wer(references, predictions)\ncer_score = cer(references, predictions)\n\nprint(f\"\\nWER (Hindi): {wer_score:.4f}\")\nprint(f\"CER (Hindi): {cer_score:.4f}\")\n\nprint(\"\\n--- Sample Inference (First 5) ---\")\nfor i in range(5):\n    print(f\"\\nReference {i+1}:  {references[i]}\")\n    print(f\"Prediction {i+1}: {predictions[i]}\")\n\nparam_size = sum(p.numel() for p in model.parameters()) * 4 / (1024 ** 2)\nprint(f\"\\nModel Size: {param_size:.2f} MB\")\n\nmodel.save_pretrained(\"/kaggle/working/whisper-hindi-model\")\nprocessor.save_pretrained(\"/kaggle/working/whisper-hindi-model\")\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T06:24:02.149592Z","iopub.execute_input":"2025-04-14T06:24:02.150013Z","iopub.status.idle":"2025-04-14T06:37:38.923480Z","shell.execute_reply.started":"2025-04-14T06:24:02.149966Z","shell.execute_reply":"2025-04-14T06:37:38.922448Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.1.0)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.8)\nRequirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.13.0)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1183 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a4f95b6046d494aabab4d1f6dc46a52"}},"metadata":{}},{"name":"stdout","text":"\nWER (Hindi): 3.9311\nCER (Hindi): 3.7089\n\n--- Sample Inference (First 5) ---\n\nReference 1:  प्रसिद्द कबीर अध्येता, पुरुषोत्तम अग्रवाल का यह शोध आलेख, उस रामानंद की खोज करता है\nPrediction 1:  Precise de cabir adheta, purushottam agraval kaihashod alik usramanandaki khuchkarthahe.\n\nReference 2:  किन्तु आधुनिक पांडित्य, न सिर्फ़ एक ब्राह्मण रामानंद के, एक जुलाहे कबीर का गुरु होने से, बल्कि दोनों के समकालीन होने से भी, इनकार करता है\nPrediction 2:  But the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day, the next day,\n\nReference 3:  उस पर, इन चार कवियों का गहरा असर है\nPrediction 3:  Uspir 4 KVGHRA ASARH\n\nReference 4:  इसे कई बार मंचित भी किया गया है\nPrediction 4:  This is the only way to get rid of the problem.\n\nReference 5:  यहाँ प्रस्तुत है, हिन्दी कवि कथाकार, तेजी ग्रोवर के अंग्रेज़ी के मार्फ़त किए गए अनुवाद के, कुछ अंश\nPrediction 5:  Here the rest of the Kavikatthakar was also the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the one who had been the\n\nModel Size: 144.05 MB\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [1, 2, 7, 8, 9, 10, 14, 25, 26, 27, 28, 29, 31, 58, 59, 60, 61, 62, 63, 90, 91, 92, 93, 359, 503, 522, 542, 873, 893, 902, 918, 922, 931, 1350, 1853, 1982, 2460, 2627, 3246, 3253, 3268, 3536, 3846, 3961, 4183, 4667, 6585, 6647, 7273, 9061, 9383, 10428, 10929, 11938, 12033, 12331, 12562, 13793, 14157, 14635, 15265, 15618, 16553, 16604, 18362, 18956, 20075, 21675, 22520, 26130, 26161, 26435, 28279, 29464, 31650, 32302, 32470, 36865, 42863, 47425, 49870, 50254, 50258, 50358, 50359, 50360, 50361, 50362], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}],"execution_count":3}]}