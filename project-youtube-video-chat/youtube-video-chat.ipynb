{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ac5c9d",
   "metadata": {},
   "source": [
    "## RAG - Retrieval Augmented Generation\n",
    "\n",
    "RAG is a way to make the language model smarter by giving it extra information at the time we ask the question.\n",
    "\n",
    "Components:\n",
    "1. Indexing: Build external knowledge base\n",
    "    - Document Ingestion\n",
    "    - Text Chunking\n",
    "    - Embedding Generation\n",
    "    - Storage in Vector Store Database\n",
    "2. Retreival: Extract relevant information for a query\n",
    "    - Generate Embedding vector of the query\n",
    "    - Search\n",
    "    - Ranking\n",
    "    - Return top K\n",
    "3. Augmentation: Prompt creation using Query + Context (From retreival step)\n",
    "4. Generation: LLM generates response based on the augmented prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d29cb7",
   "metadata": {},
   "source": [
    "### Improvement areas - Advance RAG\n",
    "1. UI Based enhancements\n",
    "\n",
    "2. Evaluation\n",
    "    1. Ragas [faithfullness, answer_relevancy, context_precision, context_recall]\n",
    "    2. LangSmith\n",
    "\n",
    "3. Indexing\n",
    "    1. Document Ingestion\n",
    "    2. Text Splitting\n",
    "    3. Vector Store\n",
    "\n",
    "4. Retrieval\n",
    "    1. Pre-Retrieval\n",
    "        1. Query re-writing using LLM\n",
    "        2. Multi query generation\n",
    "        3. Domain aware routing (Using different retreivars for different domain queries)\n",
    "    2.  During Retrieval\n",
    "        1. MMR\n",
    "        2. Hybrid Retrieval\n",
    "        3. Reranking\n",
    "    3. Post Retrieval\n",
    "        1. Contextual Compression\n",
    "\n",
    "5. Augmentation\n",
    "    1. Prompt Templating\n",
    "    2. Answer grounding\n",
    "    3. Context window optimisation\n",
    "\n",
    "6. Generation\n",
    "    1. Answer with citation\n",
    "    2. Guard railing\n",
    "\n",
    "7. System Design\n",
    "    1. Multimodal\n",
    "    2. Agentic\n",
    "    3. Memory Based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776b64d1",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfd4dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# os.environ['HF_HOME']=\"/Users/nikhil20.sharma/Desktop/langchain/.cache\"\n",
    "os.environ['HF_HOME']=\"/Users/nikhil20.sharma/Desktop/hf-cache\"\n",
    "\n",
    "# Print all environment variables loaded from .env\n",
    "print(\"Loaded Environment Variables:\")\n",
    "for key, value in os.environ.items():\n",
    "    if key in ['OPENAI_API_KEY', 'LANGSMITH_AIP_KEY', 'HUGGINGFACE_TOKEN']:\n",
    "        # Mask sensitive values for security\n",
    "        masked_value = value[:8] + \"...\" + value[-4:] if value else value\n",
    "        print(f\"- {key}: {masked_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bdeb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d3e61a",
   "metadata": {},
   "source": [
    "### Step 1a - Indexing (Document Ingestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b00f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_id = \"Gfr50f6ZBvo\" # only the ID, not full URL\n",
    "try:\n",
    "    # If you don’t care which language, this returns the “best” one\n",
    "    transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"en\"])\n",
    "\n",
    "    # Flatten it to plain text\n",
    "    transcript = \" \".join(chunk[\"text\"] for chunk in transcript_list)\n",
    "    print(transcript)\n",
    "\n",
    "except TranscriptsDisabled:\n",
    "    print(\"No captions available for this video.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd986b6",
   "metadata": {},
   "source": [
    "### Step 1b - Indexing (Text Splitting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703517f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = splitter.create_documents([transcript])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b07e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239ff6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1342a49",
   "metadata": {},
   "source": [
    "### Step 1c & 1d - Indexing (Embedding Generation and Storing in Vector Store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5322676",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd998af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.index_to_docstore_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b3c7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.get_by_ids(['2436bdb8-3f5f-49c6-8915-0c654c888700'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d241bd42",
   "metadata": {},
   "source": [
    "### Step 2 - Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e61b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b3a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.invoke('What is deepmind')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4139beea",
   "metadata": {},
   "source": [
    "### Step 3 - Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bf1a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbf4ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "      You are a helpful assistant.\n",
    "      Answer ONLY from the provided transcript context.\n",
    "      If the context is insufficient, just say you don't know.\n",
    "\n",
    "      {context}\n",
    "      Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables = ['context', 'question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de7ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is the topic of nuclear fusion discussed in this video? if yes then what was discussed\"\n",
    "retrieved_docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d666ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9885bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606028be",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})\n",
    "final_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97dd4548",
   "metadata": {},
   "source": [
    "### Step 4 - Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1fda5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm.invoke(final_prompt)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6bb63a",
   "metadata": {},
   "source": [
    "## Building a Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e02add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c35e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(retrieved_docs):\n",
    "  context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "  return context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74192aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain = RunnableParallel({\n",
    "    'context': retriever | RunnableLambda(format_docs),\n",
    "    'question': RunnablePassthrough()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5946680",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_chain.invoke('who is Demis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007225fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e218b",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_chain = parallel_chain | prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c88a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_chain.invoke('Can you summarize the video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189b252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5815d0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9868ed3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f89c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
